## WILDS WDL for performing RNA-seq alignment using STAR's two-pass methodology.
## Designed to be a modular component within the WILDS ecosystem that can be used
## independently or integrated with other WILDS workflows.

version 1.0

import "https://raw.githubusercontent.com/getwilds/wilds-wdl-library/refs/heads/switch-test-data/modules/ww-testdata/ww-testdata.wdl" as ww_testdata

struct StarSample {
    String name
    File r1
    File r2
}

workflow star_example {
  meta {
    author: "Taylor Firman"
    email: "tfirman@fredhutch.org"
    description: "WDL workflow for RNA-seq alignment via STAR"
    url: "https://github.com/getwilds/ww-star"
    outputs: {
        star_bam: "STAR alignment output BAM files for each sample",
        star_bai: "Index files for the STAR alignment BAM files",
        star_gene_counts: "Gene count files generated by STAR for each sample",
        star_log_final: "Final log files from STAR alignment for each sample",
        star_log_progress: "Progress log files from STAR alignment for each sample",
        star_log: "Main log files from STAR alignment for each sample",
        star_sj: "Splice junction files from STAR alignment for each sample",
        validation_report: "validation report confirming all expected outputs were generated"
    }
  }

  parameter_meta {
    samples: "List of sample objects, each containing name, r1/r2 fastq files, and condition information"
    ref_fasta: "Reference genome FASTA file"
    ref_gtf: "Reference genome GTF annotation file"
    sjdb_overhang: "Length of the genomic sequence around the annotated junction to be used in constructing the splice junctions database"
    genome_sa_index_nbases: "Length (bases) of the SA pre-indexing string, typically between 10-15 (scales with genome size)"
    cpus: "Number of CPU cores allocated for each task in the workflow"
    memory_gb: "Memory allocated for each task in the workflow in GB"
  }

  input {
    Array[StarSample]? samples
    File? ref_fasta
    File? ref_gtf
    Int sjdb_overhang = 100
    Int genome_sa_index_nbases = 14
    Int cpus = 2
    Int memory_gb = 8
  }

  # Determine which genome files to use
  if (!defined(ref_fasta) || !defined(ref_gtf)) {
    call ww_testdata.download_ref_data { }
  }
  File genome_fasta = select_first([ref_fasta, download_ref_data.fasta])
  File genome_gtf = select_first([ref_gtf, download_ref_data.gtf])

  call build_index { input:
      reference_fasta = genome_fasta,
      reference_gtf = genome_gtf,
      sjdb_overhang = sjdb_overhang,
      genome_sa_index_nbases = genome_sa_index_nbases,
      memory_gb = memory_gb,
      cpu_cores = cpus
  }

  # If no samples provided, download demonstration data from SRA
  if (!defined(samples)) {
    call ww_testdata.download_fastq_data { }
  }

  # Create samples array - either from input or from SRA download
  Array[StarSample] final_samples = if defined(samples) then select_first([samples]) else [
    {
      "name": "demo_sample",
      "r1": select_first([download_fastq_data.r1_fastq]),
      "r2": select_first([download_fastq_data.r2_fastq])
    }
  ]

  scatter (sample in final_samples) {
    call align_two_pass { input:
        star_genome_tar = build_index.star_index_tar,
        r1 = sample.r1,
        r2 = sample.r2,
        name = sample.name,
        sjdb_overhang = sjdb_overhang,
        memory_gb = memory_gb,
        cpu_cores = cpus
    }
  }

  call validate_outputs { input:
    bam_files = align_two_pass.bam,
    bai_files = align_two_pass.bai,
    gene_count_files = align_two_pass.gene_counts
  }

  output {
    Array[File] star_bam = align_two_pass.bam
    Array[File] star_bai = align_two_pass.bai
    Array[File] star_gene_counts = align_two_pass.gene_counts
    Array[File] star_log_final = align_two_pass.log_final
    Array[File] star_log_progress = align_two_pass.log_progress
    Array[File] star_log = align_two_pass.log
    Array[File] star_sj = align_two_pass.sj_out
    File validation_report = validate_outputs.report
  }
}

task build_index {
  meta {
    description: "Task for building the STAR index files from fasta/gtf."
    outputs: {
        star_index_tar: "Compressed tarball containing the STAR genome index for future alignment steps"
    }
  }

  parameter_meta {
    reference_fasta: "Reference genome FASTA file"
    reference_gtf: "Reference genome GTF annotation file"
    sjdb_overhang: "Length of the genomic sequence around the annotated junction to be used in constructing the splice junctions database"
    genome_sa_index_nbases: "Length (bases) of the SA pre-indexing string, typically between 10-15 (scales with genome size)"
    memory_gb: "Memory allocated for the task in GB"
    cpu_cores: "Number of CPU cores allocated for the task"
  }

  input {
    File reference_fasta
    File reference_gtf
    Int sjdb_overhang = 100
    Int genome_sa_index_nbases = 14
    Int memory_gb = 64
    Int cpu_cores = 8
  }

  command <<<
    set -eo pipefail
    
    mkdir star_index

    echo "Building STAR index..."
    STAR \
      --runMode genomeGenerate \
      --runThreadN ~{cpu_cores} \
      --genomeDir star_index \
      --genomeFastaFiles "~{reference_fasta}" \
      --sjdbGTFfile "~{reference_gtf}" \
      --sjdbOverhang ~{sjdb_overhang} \
      --genomeSAindexNbases ~{genome_sa_index_nbases}

    tar -czf star_index.tar.gz star_index/*
  >>>

  output {
    File star_index_tar = "star_index.tar.gz"
  }

  runtime {
    docker: "getwilds/star:2.7.6a"
    memory: "~{memory_gb} GB"
    cpu: cpu_cores
  }
}

task align_two_pass {
  meta {
    description: "Task for aligning RNA-seq reads using STAR's two-pass technique."
    outputs: {
        bam: "Aligned reads in sorted BAM format",
        bai: "Index file for the aligned BAM file",
        gene_counts: "Gene-level read counts generated by STAR",
        log_final: "Final summary log of the STAR alignment process",
        log_progress: "Progress log containing time and resource usage during alignment",
        log: "Main log file from STAR containing detailed alignment information",
        sj_out: "Splice junction file with coordinates of detected splice junctions"
    }
  }

  parameter_meta {
    star_genome_tar: "Compressed tarball containing STAR genome index"
    r1: "FASTQ file for read 1"
    r2: "FASTQ file for read 2"
    name: "Sample name to include in output filenames"
    sjdb_overhang: "Length of the genomic sequence around the annotated junction"
    memory_gb: "Memory allocated for the task in GB"
    cpu_cores: "Total number of CPU cores allocated for the task"
    star_threads: "Number of threads to use for STAR alignment (subset of cpu_cores)"
  }

  input {
    File star_genome_tar
    File r1
    File r2
    String name
    Int sjdb_overhang = 100
    Int memory_gb = 62
    Int cpu_cores = 8
    Int star_threads = 6
  }

  command <<<
    set -eo pipefail

    echo "Extracting STAR reference..."
    tar -xvf "~{star_genome_tar}"

    echo "Starting STAR alignment..."
    STAR \
      --genomeDir star_index \
      --readFilesIn "~{r1}" "~{r2}" \
      --runThreadN ~{star_threads} \
      --readFilesCommand zcat \
      --sjdbOverhang ~{sjdb_overhang} \
      --outSAMtype BAM SortedByCoordinate \
      --twopassMode Basic \
      --outTmpDir _STARtmp \
      --outFileNamePrefix "./" \
      --quantMode GeneCounts \
      --quantTranscriptomeBAMcompression 5 

    # Clean up temporary directories
    rm -rf star_index _STARpass1 _STARgenome 2>/dev/null || true

    mv Aligned.sortedByCoord.out.bam \
      "~{name}.Aligned.sortedByCoord.out.bam"
    mv ReadsPerGene.out.tab "~{name}.ReadsPerGene.out.tab"
    mv Log.final.out "~{name}.Log.final.out"
    mv Log.progress.out "~{name}.Log.progress.out"
    mv Log.out "~{name}.Log.out"
    mv SJ.out.tab "~{name}.SJ.out.tab"

    samtools index "~{name}.Aligned.sortedByCoord.out.bam"
  >>>

  output {
    File bam = "~{name}.Aligned.sortedByCoord.out.bam"
    File bai = "~{name}.Aligned.sortedByCoord.out.bam.bai"
    File gene_counts = "~{name}.ReadsPerGene.out.tab"
    File log_final = "~{name}.Log.final.out"
    File log_progress = "~{name}.Log.progress.out"
    File log = "~{name}.Log.out"
    File sj_out = "~{name}.SJ.out.tab"
  }

  runtime {
    docker: "getwilds/star:2.7.6a"
    memory: "~{memory_gb} GB"
    cpu: cpu_cores
  }
}

task validate_outputs {
  meta {
    description: "Validate that all expected STAR output files were generated correctly"
    outputs: {
        report: "Validation report summarizing file checks and alignment statistics"
    }
  }

  parameter_meta {
    bam_files: "Array of BAM files to validate"
    bai_files: "Array of BAM index files to validate"
    gene_count_files: "Array of gene count files to validate"
  }

  input {
    Array[File] bam_files
    Array[File] bai_files
    Array[File] gene_count_files
  }

  command <<<
    set -eo pipefail
    
    echo "=== STAR Alignment Validation Report ===" > validation_report.txt
    echo "" >> validation_report.txt
    
    # Arrays for bash processing
    bam_files=~{sep=" " bam_files}
    bai_files=~{sep=" " bai_files}
    gene_count_files=~{sep=" " gene_count_files}
    
    validation_passed=true
    total_mapped_reads=0
    
    # Check each sample
    for i in "${!bam_files[@]}"; do
      bam_file="${bam_files[$i]}"
      bai_file="${bai_files[$i]}"
      gene_count_file="${gene_count_files[$i]}"
      
      echo "--- Sample: $bam_file ---" >> validation_report.txt
      
      # Check BAM file exists and is not empty
      if [[ -f "$bam_file" && -s "$bam_file" ]]; then
        bam_size=$(stat -c%s "$bam_file")
        echo "BAM file: $bam_file (${bam_size} bytes)" >> validation_report.txt
        
        # Try to get alignment stats from samtools if available
        if command -v samtools &> /dev/null; then
          mapped_reads=$(samtools view -c -F 4 "$bam_file" 2>/dev/null || echo "N/A")
          total_reads=$(samtools view -c "$bam_file" 2>/dev/null || echo "N/A")
          echo "  Total reads: $total_reads" >> validation_report.txt
          echo "  Mapped reads: $mapped_reads" >> validation_report.txt
          
          if [[ "$mapped_reads" =~ ^[0-9]+$ ]]; then
            total_mapped_reads=$((total_mapped_reads + mapped_reads))
          fi
        fi
      else
        echo "BAM file: $bam_file - MISSING OR EMPTY" >> validation_report.txt
        validation_passed=false
      fi
      
      # Check BAI file exists
      if [[ -f "$bai_file" ]]; then
        bai_size=$(stat -c%s "$bai_file")
        echo "BAI file: $bai_file (${bai_size} bytes)" >> validation_report.txt
      else
        echo "BAI file: $bai_file - MISSING" >> validation_report.txt
        validation_passed=false
      fi
      
      # Check gene counts file exists and has content
      if [[ -f "$gene_count_file" && -s "$gene_count_file" ]]; then
        gene_count_size=$(stat -c%s "$gene_count_file")
        gene_count_lines=$(wc -l < "$gene_count_file" 2>/dev/null || echo "N/A")
        echo "Gene counts file: $gene_count_file (${gene_count_size} bytes, ${gene_count_lines} lines)" >> validation_report.txt
      else
        echo "Gene counts file: $gene_count_file - MISSING OR EMPTY" >> validation_report.txt
        validation_passed=false
      fi
      
      echo "" >> validation_report.txt
    done
    
    # Overall summary
    echo "=== Validation Summary ===" >> validation_report.txt
    echo "Total samples processed: ${#bam_files[@]}" >> validation_report.txt
    if [[ "$validation_passed" == "true" ]]; then
      echo "Overall Status: PASSED" >> validation_report.txt
    else
      echo "Overall Status: FAILED" >> validation_report.txt
      exit 1
    fi
    
    # Also output to stdout for immediate feedback
    cat validation_report.txt
  >>>

  output {
    File report = "validation_report.txt"
  }

  runtime {
    docker: "getwilds/star:2.7.6a"
    memory: "2 GB"
    cpu: 1
  }
}
